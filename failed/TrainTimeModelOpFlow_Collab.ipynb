{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainTimeModelOpFlow_Collab.ipynb","provenance":[],"private_outputs":true,"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DfcRmwqY-Q7G","colab_type":"text"},"source":["Preprocessing"]},{"cell_type":"code","metadata":{"id":"1tNRb6LM-UVV","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import cv2 as cv\n","import h5py\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XRsfvOE-ta6","colab_type":"code","colab":{}},"source":["vidPath=r\"/content/train.mp4\"\n","imgStoragePath=r\"/content/IMG\"\n","\n","IMGList=[]\n","def write_frames():\n","    op_flows=[]\n","    frames=[]\n","    count=0\n","    vidCap=cv.VideoCapture(r\"/content/train.mp4\")\n","    success=True\n","    while success:\n","        if(count%1000==0) and count >0:\n","            print(count)\n","        success,frame1=vidCap.read()\n","        if (success == True):\n","            frame1=cv.cvtColor(frame1,cv.COLOR_BGR2RGB)\n","            frame1=cv.resize(frame1, (0,0), fx=0.5, fy=0.5) \n","            name=imgStoragePath\n","            filename=str(count)+r\".jpg\"\n","            IMGList.append(os.path.join(name, filename))\n","            cv.imwrite(os.path.join(name, filename),frame1)  \n","            count+=1\n","        else:\n","            print(count)\n","            print(\"video reading completed\")\n","            continue\n","    return count\n","\n","Total_frames=write_frames()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5_99-z8BDV6","colab_type":"code","colab":{}},"source":["print(Total_frames,' :Total Frames')\n","\n","print('Size of FileList: ',len(IMGList))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"deezUi3PBHyS","colab_type":"code","colab":{}},"source":["hdf5_path = r\"/content/train.hdf5\"\n","resize_size=(240, 320, 2)\n","resize_frame_size=(240, 320, 3)\n","'''Only use to reset dataset'''\n","with h5py.File(hdf5_path, \"w\") as f:\n","    f.create_dataset(\"frames\", shape = (1, resize_frame_size[0], resize_frame_size[1], resize_frame_size[2]),\n","                    maxshape = (None, resize_frame_size[0], resize_frame_size[1], resize_frame_size[2]), \n","                    chunks = (1, resize_frame_size[0], resize_frame_size[1], resize_frame_size[2]))\n","    f.create_dataset(\"speeds\", shape = (1,1), maxshape = (None,1))\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUfRN4JkBZiq","colab_type":"code","colab":{}},"source":["def write_hdf5(hdf5_path, frames, speeds):\n","    with h5py.File(hdf5_path) as f:\n","        print(len(frames), len(speeds))\n","        print(f[\"frames\"], f[\"speeds\"])\n","        f[\"frames\"].resize(f[\"frames\"].len() + len(frames), axis = 0)\n","        f[\"speeds\"].resize(f[\"speeds\"].len() + len(speeds), axis = 0)\n","        f[\"frames\"][-len(frames):] = frames\n","        f[\"speeds\"][-len(speeds):] = speeds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SRxMwG2BgtF","colab_type":"code","colab":{}},"source":["def opticalFlowDense(image_current,image_next):\n","    image_current=np.array(image_current)\n","    image_next=np.array(image_current)\n","    \n","    #convert to grayscale\n","    gray_current=cv.cvtColor(image_current,cv.COLOR_RGB2GRAY)\n","    gray_next=cv.cvtColor(image_next,cv.COLOR_RGB2GRAY)\n","    flow=cv.calcOpticalFlowFarneback(gray_current,gray_next,None,0.5,1,15,2,5,1.3,0)\n","    return flow\n","\n","\n","def flipimage(image_current, image_next):\n","    image_current=cv.flip(image_current, 1)\n","    image_next=cv.flip(image_next,1)\n","    return image_current,image_next\n","\n","def augment(image_current):\n","    brightness=np.random.uniform(0.5,1.5)\n","    image_current_1 = cv.cvtColor(image_current,cv.COLOR_RGB2HSV)\n","    image_current_1[:,:,2] = image_current_1[:,:,2]*brightness\n","    \n","    image_current_1 = cv.cvtColor(image_current_1,cv.COLOR_HSV2RGB)\n","    \n","    return image_current_1\n","\n","def flipimage(image_current):\n","    image_current=cv.flip(image_current, 1)\n","    return image_current\n","\n","def augment(image_current, image_next):\n","    brightness=np.random.uniform(0.5,1.5)\n","    image_current_1 = cv.cvtColor(image_current,cv.COLOR_RGB2HSV)\n","    image_current_1[:,:,2] = image_current_1[:,:,2]*brightness\n","    \n","    image_next_1 = cv.cvtColor(image_next,cv.COLOR_RGB2HSV)\n","    image_next_1[:,:,2] = image_next_1[:,:,2]*brightness\n","    \n","    image_current_1 = cv.cvtColor(image_current_1,cv.COLOR_HSV2RGB)\n","    image_next_1 = cv.cvtColor(image_next_1,cv.COLOR_HSV2RGB)\n","    \n","    return image_current_1,image_next_1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgUgcMtABp1b","colab_type":"code","colab":{}},"source":["import csv\n","\n","speeds=[]\n","with open(r\"/content/train.txt\") as csvfile:\n","    reader=csv.reader(csvfile)\n","    for speed in reader:\n","        speeds.append(speed)\n","\n","#remove first elem\n","print(len(speeds))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5jH-Rf9B2rN","colab_type":"code","colab":{}},"source":["Sequence_size=len(speeds)\n","print(Sequence_size, ': Sequence Size')\n","\n","Batch_size=500\n","print(Batch_size,' : BatchSize')\n","\n","Num_batches=int(np.ceil(Sequence_size/Batch_size))\n","print(Num_batches,' : Number of Batches')\n","\n","\n","All_indices=[item for item in range(1,Sequence_size)]\n","print(All_indices[-1],'Last elem')\n","print(All_indices[0],'First elem')\n","\n","\n","#print(All_indices,'All indices')\n","\n","def generate_indices(Batch_num):\n","    return All_indices[Batch_num*Batch_size:(Batch_num+1)*Batch_size]\n","\n","print(generate_indices(203))\n","\n","print(generate_indices(0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6ce7uATB-Xn","colab_type":"code","colab":{}},"source":["def make_op_flow_video():\n","    count=0\n","    for batch in range(0,Num_batches):\n","        #print(generate_indices(batch))\n","        indexes=generate_indices(batch)\n","        frames=[]\n","        speed=[]\n","        for index in indexes:\n","            #print([indexes[i],indexes[i+1]])\n","            \n","            if(count%1000==0) and count >0:\n","                print(count)\n","            \n","            frame2=cv.imread(IMGList[index])\n","            frame2=cv.cvtColor(frame2,cv.COLOR_BGR2RGB)\n","            \n","            \n","            frames.append(np.array(frame2))\n","            speed.append(speeds[index])\n","            count+=1\n","        \n","        frames=np.array(frames,dtype=np.uint8)\n","        speed=np.array(speed)\n","        speed=speed.astype(float)\n","        write_hdf5(hdf5_path, frames, speed)\n","    \n","    print(\"Completed Video Processing\")\n","    return count        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQIvPXYwCYys","colab_type":"code","colab":{}},"source":["print(\"Starting\")\n","\n","print(\"Nothing\")\n","count=make_op_flow_video()\n","print(\"Complete: \",count)\n","\n","print('check')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSIDJshEE-hT","colab_type":"code","colab":{}},"source":["op_hdf5_path = r\"/content/op1.hdf5\"\n","with h5py.File(op_hdf5_path, \"w\") as f:\n","    f.create_dataset(\"op_flow\", shape = (1, resize_size[0], resize_size[1], resize_size[2]),\n","                    maxshape = (None, resize_size[0], resize_size[1], resize_size[2]), \n","                    chunks = (1, resize_size[0], resize_size[1], resize_size[2]))\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRk1Md-AFVD-","colab_type":"code","colab":{}},"source":["def write_op_hdf5(hdf5_path, op_flows):\n","    with h5py.File(hdf5_path) as f:\n","        print( len(op_flows))\n","        print( f[\"op_flow\"])\n","        f[\"op_flow\"].resize(f[\"op_flow\"].len() + len(op_flows), axis = 0)\n","        f[\"op_flow\"][-len(op_flows):] = op_flows\n","\n","def opticalFlowDense(image_current, image_next):\n","    \"\"\"\n","    Args:\n","        image_current : RGB image\n","        image_next : RGB image\n","    return:\n","        optical flow magnitude and angle and stacked in a matrix\n","    \"\"\"\n","    image_current = np.array(image_current)\n","    image_next = np.array(image_next)\n","    gray_current = cv.cvtColor(image_current, cv.COLOR_RGB2GRAY)\n","    gray_next = cv.cvtColor(image_next, cv.COLOR_RGB2GRAY)\n","    flow = cv.calcOpticalFlowFarneback(gray_current, gray_next, None, 0.5, 1, 15, 2, 5, 1.3, 0)\n","    return flow\n","\n","def dense_op():\n","    op_flows = []\n","    count = 0\n","    vidcap = cv.VideoCapture(vidPath)\n","    success,frame1 = vidcap.read()\n","    frame1 = cv.cvtColor(frame1, cv.COLOR_BGR2RGB)\n","    frame1 = cv.resize(frame1, (0,0), fx=0.5, fy=0.5) \n","    while success:\n","        if (count % 100 == 0) and count > 0:\n","            print(count)\n","        success,frame2 = vidcap.read()\n","        if success == True:\n","            frame2 = cv.cvtColor(frame2, cv.COLOR_BGR2RGB)\n","            frame2 = cv.resize(frame2, (0,0), fx=0.5, fy=0.5) \n","            frame1,frame2=augment(frame1,frame2)\n","            flow = opticalFlowDense(frame1, frame2)\n","            op_flows.append(flow)\n","            frame1 = frame2\n","            count+=1\n","        else:\n","            print(\"video reading completed\")\n","            continue\n","    \n","    write_op_hdf5(op_hdf5_path,np.array(op_flows))\n","    return count\n","dense_op()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpwF5nGE-NJk","colab_type":"text"},"source":["\n","\n","End of Prepeocessing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pPQY3KRQDFwO","colab":{}},"source":["import os\n","import numpy as np\n","import cv2 as cv\n","import h5py\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.layers import Conv2D, MaxPool2D, CuDNNGRU, GlobalMaxPool2D, Reshape, GRU, \\\n","concatenate, Input, TimeDistributed , Dense, BatchNormalization, SpatialDropout2D, SpatialDropout1D, Dropout, GlobalAvgPool2D, Flatten\n","from keras import Model\n","from keras.applications import Xception\n","import keras.backend as k\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import mean_squared_error\n","\n","from keras.models import Sequential\n","from keras.layers import Cropping2D\n","from keras.layers import Convolution2D, MaxPooling2D, Dropout,ConvLSTM2D,TimeDistributed\n","from keras.layers import Conv2D, MaxPool2D, CuDNNGRU, GlobalMaxPool2D, Reshape, GRU, \\\n","concatenate, Input, TimeDistributed, Dense, BatchNormalization, SpatialDropout2D, SpatialDropout1D, Dropout, GlobalAvgPool2D, Flatten\n","from keras.layers.core import Dense,Activation,Flatten,Lambda\n","from keras.layers import Lambda\n","from math import ceil\n","from keras import optimizers\n","from keras.layers import LSTM\n","from keras.layers import CuDNNGRU\n","from keras.layers import ELU\n","from sklearn.model_selection import train_test_split, KFold\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import mean_squared_error\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3YryN0zfRVY7","colab":{}},"source":["import glob \n","\n","hdf5_paths =  glob.glob(r\"/content/train*.hdf5\")\n","op_hdf5_paths =  glob.glob(r\"/content/op*.hdf5\")\n","augFactor=4\n","\n","hdf5_paths.sort()\n","op_hdf5_paths.sort()\n","\n","print(hdf5_paths)\n","print(op_hdf5_paths)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gAa-iDR-DFwU","scrolled":true,"colab":{}},"source":["for path in op_hdf5_paths:\n","      with h5py.File(path, \"r\") as g:\n","        print(\"mean intensity of optical flow:\" , g[\"op_flow\"][1].mean())\n","        print(\"mean intensity of optical flow:\" , g[\"op_flow\"][0].mean())\n","        print(\"mean intensity of optical flow:\" , g[\"op_flow\"][20339].mean())\n","        print((g[\"op_flow\"]).shape,'opFlows size')\n","    \n","for path in hdf5_paths:\n","      with h5py.File(path, \"r\") as f:\n","        print(\"mean intensity of optical flow:\", f[\"frames\"][5601].mean())\n","        plt.imshow(f[\"frames\"][5601]/255)\n","        data_size=f[\"speeds\"].shape[0]\n","        print((f[\"frames\"]).shape,'frame size')\n","  \n","\n","train_size=int(data_size)\n","data_size*=augFactor\n","\n","print(train_size,'number of speed data samples')\n","print(data_size,'real Training Size')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ydKeDXmODFwX"},"source":["## Developing a time history model\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gcCu6t6TDFwY","colab":{}},"source":["from statistics import median as median\n","\n","def generate_indices(time_history,train_size):\n","# All we need to do is store the indices\n","    FrameIndices=[]\n","    SpeedIndices=[]\n","    \n","    print(train_size)\n","    for j in range(0,train_size-time_history+1):\n","        tempFrame=[]\n","        for i in range(0,time_history):\n","            tempFrame.append(i+j)\n","        if time_history==2:            \n","            SpeedIndices.append(min(tempFrame))\n","        else:\n","            SpeedIndices.append(median(tempFrame))\n","        FrameIndices.append(tempFrame)\n","    return FrameIndices,SpeedIndices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Hxeas8v_0I_2","colab_type":"code","colab":{}},"source":["time_history = 2\n","\n","train_size=int(data_size/augFactor)\n","FrameIndices,SpeedIndices=generate_indices(time_history,train_size)\n","train_size=len(FrameIndices)\n","print(train_size,'Revised Train Size')\n","\n","train_size=len(SpeedIndices)\n","print(train_size,'Revised Train Size Again')\n","\n","print(FrameIndices[-1],'last Frame slice')\n","print(SpeedIndices[-1], 'last Speed slice')\n","\n","print()\n","print('Checking if within indices:')\n","for path in hdf5_paths:\n","    with h5py.File(path, \"r\") as f:\n","        plt.imshow(f[\"frames\"][FrameIndices[-1][-1]]/255)\n","        print(f[\"speeds\"][SpeedIndices[-1]],'Last Speed Indice Value')\n","\n","for path in op_hdf5_paths:\n","    with h5py.File(path, \"r\") as f:\n","           print(\"mean intensity of optical flow:\" , f[\"op_flow\"][FrameIndices[-1][-1]].mean())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"znkqNYo7DFwe"},"source":["## Generator Class"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oC8QJ4m2DFwe","colab":{}},"source":["class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, hdf5_paths,op_hdf5_paths,FrameIndices,SpeedIndices,train_size,indexes = None, validation_mode = False):\n","        \n","        self.hdf5_paths = hdf5_paths\n","        self.op_hdf5_paths=op_hdf5_paths\n","        self.FrameIndices=FrameIndices\n","        self.SpeedIndices=SpeedIndices\n","        \n","        \n","        if indexes is None:\n","            with indexes is None:\n","                 with h5py.File(self.hdf5_path, \"r\") as f:\n","                        self.indexes=np.arrange(train_size)\n","        else:\n","            self.indexes=indexes\n","        self.batch_size=batch_size\n","        self.validation_mode=validation_mode\n","        if self.validation_mode==False:\n","            print(\"shuffling\")\n","            self.on_epoch_end()\n","       \n","        \n","            \n","    def __len__(self):\n","        # Denotes the number of batches per epoch\n","        return int(np.ceil(len(self.indexes)/self.batch_size))\n","    \n","    def __getitem__(self,index):\n","        # Generate indexes of the batch\n","        indexes=self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        \n","        # Generate the data\n","        return self.__data_generation(indexes)\n","    \n","    def on_epoch_end(self):\n","        # updates indexes after each epoch\n","        if self.validation_mode == False:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self,indexes):\n","        # Generates data containing batch samples\n","        indexes=list(indexes)\n","        indexes.sort()## We are making the Generator Class to read the video and the speed file\n","        speeds=[]\n","        op_flow=[]\n","        \n","        for paths in self.hdf5_paths:\n","            with h5py.File(paths, \"r\") as f:\n","                for index in indexes:\n","                    #print(index,\",\",end=\"\")\n","                    speeds.append(f[\"speeds\"][self.SpeedIndices[index]])\n","                       \n","        \n","        for paths in self.op_hdf5_paths:\n","            with h5py.File(paths, \"r\") as f:\n","                for index in indexes:\n","                    op_flow.append(f[\"op_flow\"][self.FrameIndices[index]])\n","                    i=(random.randint(0,8))\n","                    \n","        op_flow=np.array(op_flow)\n","        speeds=np.array(speeds)\n","        return [op_flow,speeds]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SrlAwVwlDFwh","colab":{}},"source":["def build_model_history(history_size):\n","    \n","    op_flow_inp=Input(shape=(history_size,240,320,2))\n","    filter_size = (3,3)\n","   \n","    \n","    op_flow=TimeDistributed(Lambda(lambda x: (x / 255.0) - 0.5))(op_flow_inp)\n","    \n","    op_flow = TimeDistributed(BatchNormalization())(op_flow_inp)\n","    op_flow = TimeDistributed(Dropout(.5))(op_flow)\n","    op_flow = TimeDistributed(Conv2D(4, filter_size, activation = \"relu\", data_format = \"channels_last\"))(op_flow)\n","    op_flow = TimeDistributed(MaxPool2D())(op_flow)\n","    op_flow = TimeDistributed(Conv2D(8, filter_size, activation = \"relu\", data_format = \"channels_last\"))(op_flow)\n","    op_flow = TimeDistributed(MaxPool2D())(op_flow)\n","    op_flow = TimeDistributed(Conv2D(32, filter_size, activation = \"relu\", data_format = \"channels_last\"))(op_flow)\n","    op_flow = TimeDistributed(MaxPool2D())(op_flow)\n","    op_flow = TimeDistributed(Conv2D(64, filter_size, activation = \"relu\", data_format = \"channels_last\"))(op_flow)\n","    op_flow = TimeDistributed(Dropout(.3))(op_flow)\n","    op_flow = TimeDistributed(MaxPool2D())(op_flow)\n","    op_flow = TimeDistributed(Conv2D(128, filter_size, activation = \"relu\", data_format = \"channels_last\"))(op_flow)\n","    op_flow = TimeDistributed(MaxPool2D())(op_flow)\n","    op_flow_max = TimeDistributed(GlobalMaxPool2D())(op_flow)\n","    op_flow_avg = TimeDistributed(GlobalAvgPool2D())(op_flow)\n","    \n","    conc=concatenate([op_flow_max,op_flow_avg],axis=1)\n","    \n","    conc = SpatialDropout1D(.5)(conc)\n","    conc = GRU(256)(conc)\n","    conc = Dense(100, activation = \"relu\")(conc)\n","    conc = Dropout(.2)(conc)\n","    conc = Dense(50, activation = \"relu\")(conc)\n","    conc = Dropout(.1)(conc)\n","    result = Dense(1, activation='linear')(conc)\n","    \n","    model = Model(inputs=op_flow_inp, outputs=[result])\n","    print(model.summary())\n","    model.compile(loss=\"mse\", optimizer='adam')\n","\n","    return model\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QDXXZPoJDFwk","scrolled":true,"colab":{}},"source":["model=build_model_history(time_history)\n","train_indexes, val_indexes=train_test_split(np.arange(int(train_size)), shuffle = True, test_size = .2)\n","\n","print(train_size,'Training data size per Aug')\n","print(train_indexes,'Train indices')\n","print(val_indexes,'Val indices')\n","\n","maxIndexT=max(train_indexes)\n","maxIndexV=max(val_indexes)\n","print(maxIndexT,maxIndexV)\n","\n","minIndexT=min(train_indexes)\n","minIndexV=min(val_indexes)\n","print(minIndexT,minIndexV)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ayYOBV0kDFwn","colab":{}},"source":["train_generator=DataGenerator(50,hdf5_paths,op_hdf5_paths,FrameIndices,SpeedIndices,train_size,indexes=train_indexes,validation_mode=False)\n","valid_generator=DataGenerator(50,hdf5_paths,op_hdf5_paths,FrameIndices,SpeedIndices,train_size,indexes=val_indexes,validation_mode=True)\n","model.fit_generator(train_generator, validation_data=valid_generator, epochs = 10,callbacks=[EarlyStopping(patience=3), ModelCheckpoint(filepath=\"cnn_time_model_opflow_mid_time_2.h5\", save_weights_only=False)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxKK_skpmPwC","colab_type":"code","colab":{}},"source":["index_array = np.arange(int(train_size))\n","split_count = 5\n","num_epochs = 10\n","steps_per_epoch = None\n","kf = KFold(shuffle = False, n_splits = split_count)\n","custom_splits = list(kf.split(index_array))\n","for fold in range(split_count):\n","    train_indexes, val_indexes = custom_splits[fold]\n","    print(\"training on fold \" + str(fold))\n","    \n","    train_generator=DataGenerator(50,hdf5_paths,op_hdf5_paths,FrameIndices,SpeedIndices,train_size,indexes=train_indexes,validation_mode=False)\n","    valid_generator=DataGenerator(50,hdf5_paths,op_hdf5_paths,FrameIndices,SpeedIndices,train_size,indexes=val_indexes,validation_mode=True)\n","    model.fit_generator(train_generator, validation_data=valid_generator, epochs = 10,callbacks=[EarlyStopping(patience=3), ModelCheckpoint(filepath=\"cnn_time_model_opflow_mid_time_2_cross_training.h5\", save_weights_only=False)])\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MmRqdUWwK5L","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}