{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, CuDNNGRU, GlobalMaxPool2D, Reshape, \\\n",
    "concatenate, Input, TimeDistributed , \\\n",
    "Dense, BatchNormalization, SpatialDropout2D, SpatialDropout1D, Dropout, GlobalAvgPool2D, Flatten\n",
    "from keras import Model\n",
    "from keras.applications import Xception\n",
    "import keras.backend as k\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout,ConvLSTM2D,TimeDistributed\n",
    "from keras.layers.core import Dense,Activation,Flatten,Lambda\n",
    "from keras.layers import Lambda\n",
    "from math import ceil\n",
    "from keras import optimizers\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "hdf5_paths = glob.glob(r\"C:\\Users\\Nihar\\Google Drive\\Colab Notebooks\\data\\train\\train*.hdf5\")\n",
    "op_hdf5_paths = glob.glob(r\"C:\\Users\\Nihar\\Google Drive\\Colab Notebooks\\data\\train\\op*.hdf5\")\n",
    "augFactor=4\n",
    "\n",
    "with h5py.File(hdf5_paths[0], \"r\") as f and h5py.File(op_hdf5_paths[0], \"r\") as g:\n",
    "    data_size = len(f[\"speeds\"])\n",
    "    print(f[\"frames\"][5601].mean())\n",
    "    plt.imshow(f[\"frames\"][5601]/255)\n",
    "    speed_data = list(f[\"speeds\"])\n",
    "    print((f[\"frames\"]).shape,'frame size')\n",
    "data_size*=augFactor    \n",
    "print(len(speed_data),'number of speed data samples')\n",
    "print(data_size,'real Tran Size')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
